{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Recommender Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY_TlVHQL99q",
        "outputId": "0ee971cd-e016-4401-a166-000d590535dc"
      },
      "source": [
        "# Installing Libraries\n",
        "!pip install tflearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 26.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=465aef13558d04e5a7fc2f01ddc6421db3e24d6ee87c8a7db8e4ec26453fd180\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbvWkWuAMD3r",
        "outputId": "c161f360-19b9-44e8-fb3d-6c71913bb146"
      },
      "source": [
        "#Imports\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import os\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import numpy as np\n",
        "import tflearn\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import json\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP_Pgfw_MK-6"
      },
      "source": [
        "#Loading the intents data\n",
        "with open(\"intents.json\") as file:\n",
        "\tdata = json.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIet9zfKMYLj"
      },
      "source": [
        "#Initializing empty lists\n",
        "words = []\n",
        "labels = []\n",
        "docs_x = []\n",
        "docs_y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocNwF1E3MaVM"
      },
      "source": [
        "#Looping through our data\n",
        "for intent in data['intents']:\n",
        "\tfor pattern in intent['patterns']:\n",
        "\t\tpattern = pattern.lower()\n",
        "    #Creating a list of words\n",
        "\t\twrds = nltk.word_tokenize(pattern)\n",
        "\t\twords.extend(wrds)\n",
        "\t\tdocs_x.append(wrds)\n",
        "\t\tdocs_y.append(intent['tag'])\n",
        "\n",
        "\tif intent['tag'] not in labels:\n",
        "\t  labels.append(intent['tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOJs1rmvMhvO"
      },
      "source": [
        "#Pre-Processing the given data\n",
        "stemmer = LancasterStemmer()\n",
        "words = [stemmer.stem(w.lower()) for w in words if w not in \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "labels = sorted(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvM4MjVIMopz"
      },
      "source": [
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "for x,doc in enumerate(docs_x):\n",
        "\tbag = []\n",
        "\twrds = [stemmer.stem(w) for w in doc]\n",
        "\tfor w in words:\n",
        "\t\tif w in wrds:\n",
        "\t\t\tbag.append(1)\n",
        "\t\telse:\n",
        "\t\t\tbag.append(0)\n",
        "\toutput_row = out_empty[:]\n",
        "\toutput_row[labels.index(docs_y[x])] = 1\n",
        "\ttraining.append(bag)\n",
        "\toutput.append(output_row)\n",
        "#Converting training data into NumPy arrays\n",
        "training = np.array(training)\n",
        "output = np.array(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBtJ8v6qMwYH"
      },
      "source": [
        "#Saving data to disk\n",
        "with open(\"data.pickle\",\"wb\") as f:\n",
        "\tpickle.dump((words, labels, training, output),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hze8v8v7MyMM",
        "outputId": "25403d4f-77a2-4a0f-ddf2-31e12037babe"
      },
      "source": [
        "#Generating and Saving ML Model\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "net = tflearn.input_data(shape = [None, len(training[0])])\n",
        "net = tflearn.fully_connected(net,8)\n",
        "net = tflearn.fully_connected(net,8)\n",
        "net = tflearn.fully_connected(net,len(output[0]), activation = \"softmax\")\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)\n",
        "model.fit(training, output, n_epoch = 200, batch_size = 8, show_metric = True)\n",
        "model.save(\"model.tflearn\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.21169\u001b[0m\u001b[0m | time: 0.031s\n",
            "| Adam | epoch: 200 | loss: 0.21169 - acc: 0.9932 -- iter: 24/25\n",
            "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.19156\u001b[0m\u001b[0m | time: 0.037s\n",
            "| Adam | epoch: 200 | loss: 0.19156 - acc: 0.9938 -- iter: 25/25\n",
            "--\n",
            "INFO:tensorflow:/content/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIllJb4KM2eI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opuHiSh5M-gL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}